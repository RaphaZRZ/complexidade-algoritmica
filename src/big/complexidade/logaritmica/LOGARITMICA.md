‚ö°Ô∏è Explicando a Complexidade Algor√≠tmica Logar√≠tmica, tamb√©m conhecida como O(log N).

Vamos imaginar que voc√™ deseja encontrar uma palavra espec√≠fica em um dicion√°rio. Como um dicion√°rio cont√©m milhares de 
palavras organizadas alfabeticamente, a busca por uma palavra pode ser otimizada. Em vez de folhear p√°gina por p√°gina, 
voc√™ pode abrir o dicion√°rio no meio e verificar se a palavra desejada est√° na metade esquerda ou direita. Em seguida, 
repete o processo at√© encontr√°-la. A cada etapa, o n√∫mero de p√°ginas a serem pesquisadas √© reduzido pela metade. 
Por isso, o total de etapas necess√°rias √© proporcional ao logaritmo do n√∫mero total de p√°ginas.\
Esse √© um √≥timo exemplo do que chamamos de complexidade logar√≠tmica, representada pela nota√ß√£o O(log N).

üìå O que significa O(log n)?
A complexidade O(log N) indica que o tempo de execu√ß√£o de um algoritmo cresce logaritmicamente √† medida que a 
quantidade de dados aumenta. Ou seja, conforme a entrada do problema cresce, o tempo necess√°rio para resolv√™-lo n√£o 
aumenta na mesma propor√ß√£o, mas sim de forma significativamente mais lenta.

üîçExemplo Pr√°tico:
No c√≥digo abaixo, tentamos calcular a raiz quadrada de diferentes valores (144, 1.048.576 e 268.402.689).
Observe que a quantidade de etapas necess√°rias para encontrar a raiz de 1.048.576 (13 etapas) n√£o aumentou muito em 
rela√ß√£o √† de 268.402.689 (18 etapas), mesmo com a grande diferen√ßa num√©rica entre os dois valores. 
Isso acontece porque o crescimento segue um padr√£o logar√≠tmico.